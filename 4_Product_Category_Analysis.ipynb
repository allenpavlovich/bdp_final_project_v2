{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df180e90-bfd4-4368-9016-5352c659c456",
   "metadata": {},
   "source": [
    "# Big Data and Cloud Computing - Final Project\n",
    "\n",
    "## Product and Category Analysis\n",
    "\n",
    "### Author:\n",
    "Alen Pavlovic\n",
    "\n",
    "The University of Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87a0c2c-50bc-4ec8-9e28-84d0aef3cbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*3-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907702cb-f472-4885-be3f-c39534165100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34217d5b-9e0a-41dc-8f0e-d4f08680ec36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_DEV_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b98b4e-313f-4a7d-90f2-09b10c9b8101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Product_Category_Analysis\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfcae36-4abf-48c5-823d-0ad599d76bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DEV cleaned data...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading {'DEV' if USE_DEV_DATA else 'PRODUCTION'} cleaned data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a9a5b2-aec9-4ad8-b240-6cb74d1fb8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_DEV_DATA:\n",
    "    reviews_path = \"gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/reviews_cleaned_eda_dev\"\n",
    "    meta_path = \"gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/meta_cleaned_eda_dev\"\n",
    "else:\n",
    "    reviews_path = \"gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/cleaned_reviews\"\n",
    "    meta_path = \"gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/cleaned_metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2809780c-0e46-4dc9-9cfe-b5c878ef25c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6,191,852 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1,378,413 products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews_df = spark.read.parquet(reviews_path)\n",
    "meta_df = spark.read.parquet(meta_path)\n",
    "\n",
    "print(f\"Loaded {reviews_df.count():,} reviews\")\n",
    "print(f\"Loaded {meta_df.count():,} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762c38cf-42cf-4be6-90df-6412e2a85452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_product_aggregates(reviews_df, meta_df):\n",
    "    \"\"\"Create product-level aggregated dataset with ratings, review counts, and metadata\"\"\"\n",
    "    print(\"\\n=== CREATING PRODUCT AGGREGATES ===\")\n",
    "    \n",
    "    # Aggregate review statistics by product\n",
    "    product_stats = reviews_df.groupBy(\"parent_asin\").agg(\n",
    "        F.count(\"*\").alias(\"review_count\"),\n",
    "        F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "        F.stddev(\"rating\").alias(\"rating_std\"),\n",
    "        F.sum(F.when(F.col(\"rating\") == 5, 1).otherwise(0)).alias(\"five_star_count\"),\n",
    "        F.sum(F.when(F.col(\"rating\") == 1, 1).otherwise(0)).alias(\"one_star_count\"),\n",
    "        F.avg(\"text_length\").alias(\"avg_review_length\"),\n",
    "        F.countDistinct(\"user_id\").alias(\"unique_reviewers\"),\n",
    "        F.sum(\"helpful_vote\").alias(\"total_helpful_votes\")\n",
    "    )\n",
    "    \n",
    "    # Join with metadata to get product info including price\n",
    "    products_full = product_stats.join(\n",
    "        meta_df.select(\"parent_asin\", \"title\", \"main_category\", \"price\", \"average_rating\"),\n",
    "        on=\"parent_asin\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    # Add derived features\n",
    "    products_full = products_full.withColumn(\n",
    "        \"is_high_rated\", \n",
    "        F.when(F.col(\"avg_rating\") >= 4.9, True).otherwise(False)\n",
    "    ).withColumn(\n",
    "        \"price_range\",\n",
    "        F.when(F.col(\"price\").isNull(), \"Unknown\")\n",
    "        .when(F.col(\"price\") < 25, \"Under $25\")\n",
    "        .when(F.col(\"price\") < 50, \"$25-$50\")\n",
    "        .when(F.col(\"price\") < 100, \"$50-$100\")\n",
    "        .when(F.col(\"price\") < 200, \"$100-$200\")\n",
    "        .otherwise(\"$200+\")\n",
    "    ).withColumn(\n",
    "        \"reviews_per_reviewer\",\n",
    "        F.col(\"review_count\") / F.col(\"unique_reviewers\")\n",
    "    )\n",
    "    \n",
    "    # Cache for performance\n",
    "    products_full.cache()\n",
    "    \n",
    "    print(f\"Created aggregates for {products_full.count():,} products\")\n",
    "    \n",
    "    return products_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ceb08ab-940f-40dd-bff7-56cbffe381cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CREATING PRODUCT AGGREGATES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===================================================> (965 + 5) / 1000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created aggregates for 1,341,145 products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "products_df = create_product_aggregates(reviews_df, meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a113867-d467-4111-a48a-845a3c9f93e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_category_review_volume(products_df):\n",
    "    \"\"\"Analyze how review volume varies across product categories\"\"\"\n",
    "    print(\"\\n=== REVIEW VOLUME BY CATEGORY ANALYSIS ===\")\n",
    "    \n",
    "    # Calculate category-level statistics\n",
    "    category_stats = products_df.groupBy(\"main_category\").agg(\n",
    "        F.count(\"*\").alias(\"product_count\"),\n",
    "        F.sum(\"review_count\").alias(\"total_reviews\"),\n",
    "        F.avg(\"review_count\").alias(\"avg_reviews_per_product\"),\n",
    "        F.stddev(\"review_count\").alias(\"std_reviews_per_product\"),\n",
    "        F.max(\"review_count\").alias(\"max_reviews_single_product\"),\n",
    "        F.avg(\"avg_rating\").alias(\"category_avg_rating\"),\n",
    "        F.avg(F.when(F.col(\"price\").isNotNull(), F.col(\"price\"))).alias(\"avg_price\")\n",
    "    ).orderBy(F.col(\"total_reviews\").desc())\n",
    "    \n",
    "    category_stats_pd = category_stats.toPandas()\n",
    "    \n",
    "    # Display top categories by total review volume\n",
    "    print(\"\\nTop 10 Categories by Total Review Volume:\")\n",
    "    for idx, row in category_stats_pd.head(10).iterrows():\n",
    "        print(f\"{idx+1}. {row['main_category']}: {row['total_reviews']:,} reviews\")\n",
    "        print(f\"   - {row['product_count']:,} products\")\n",
    "        print(f\"   - Avg {row['avg_reviews_per_product']:.1f} reviews/product\")\n",
    "        print(f\"   - Category avg rating: {row['category_avg_rating']:.2f}\")\n",
    "        if pd.notna(row['avg_price']):\n",
    "            print(f\"   - Avg price: ${row['avg_price']:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    # Categories with highest review concentration\n",
    "    print(\"\\nTop 5 Categories by Average Reviews per Product:\")\n",
    "    top_concentrated = category_stats_pd.nlargest(5, 'avg_reviews_per_product')\n",
    "    for idx, row in top_concentrated.iterrows():\n",
    "        print(f\"- {row['main_category']}: {row['avg_reviews_per_product']:.1f} avg reviews/product\")\n",
    "    \n",
    "    return category_stats_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aff9403-c7de-4317-a58e-c9be5ccdeff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REVIEW VOLUME BY CATEGORY ANALYSIS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Categories by Total Review Volume:\n",
      "1. All Beauty: 1,781,597 reviews\n",
      "   - 290,519 products\n",
      "   - Avg 6.1 reviews/product\n",
      "   - Category avg rating: 4.03\n",
      "   - Avg price: $25.19\n",
      "\n",
      "2. Cell Phones & Accessories: 1,669,314 reviews\n",
      "   - 345,009 products\n",
      "   - Avg 4.8 reviews/product\n",
      "   - Category avg rating: 3.82\n",
      "   - Avg price: $20.32\n",
      "\n",
      "3. Automotive: 1,614,384 reviews\n",
      "   - 500,653 products\n",
      "   - Avg 3.2 reviews/product\n",
      "   - Category avg rating: 4.09\n",
      "   - Avg price: $79.99\n",
      "\n",
      "4. Health & Personal Care: 199,361 reviews\n",
      "   - 33,142 products\n",
      "   - Avg 6.0 reviews/product\n",
      "   - Category avg rating: 4.03\n",
      "   - Avg price: $29.28\n",
      "\n",
      "5. All Electronics: 168,038 reviews\n",
      "   - 24,015 products\n",
      "   - Avg 7.0 reviews/product\n",
      "   - Category avg rating: 3.92\n",
      "   - Avg price: $34.87\n",
      "\n",
      "6. Premium Beauty: 131,630 reviews\n",
      "   - 18,290 products\n",
      "   - Avg 7.2 reviews/product\n",
      "   - Category avg rating: 4.10\n",
      "   - Avg price: $43.91\n",
      "\n",
      "7. Amazon Home: 110,362 reviews\n",
      "   - 26,402 products\n",
      "   - Avg 4.2 reviews/product\n",
      "   - Category avg rating: 3.99\n",
      "   - Avg price: $47.65\n",
      "\n",
      "8. Tools & Home Improvement: 104,637 reviews\n",
      "   - 26,940 products\n",
      "   - Avg 3.9 reviews/product\n",
      "   - Category avg rating: 4.01\n",
      "   - Avg price: $41.04\n",
      "\n",
      "9. AMAZON FASHION: 77,561 reviews\n",
      "   - 21,364 products\n",
      "   - Avg 3.6 reviews/product\n",
      "   - Category avg rating: 4.07\n",
      "   - Avg price: $32.05\n",
      "\n",
      "10. Industrial & Scientific: 74,287 reviews\n",
      "   - 22,671 products\n",
      "   - Avg 3.3 reviews/product\n",
      "   - Category avg rating: 4.02\n",
      "   - Avg price: $39.38\n",
      "\n",
      "\n",
      "Top 5 Categories by Average Reviews per Product:\n",
      "- Sports Collectibles: 9.0 avg reviews/product\n",
      "- Appliances: 8.4 avg reviews/product\n",
      "- Amazon Devices: 8.2 avg reviews/product\n",
      "- Camera & Photo: 8.0 avg reviews/product\n",
      "- Premium Beauty: 7.2 avg reviews/product\n"
     ]
    }
   ],
   "source": [
    "category_stats = analyze_category_review_volume(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d515cd97-7046-42b5-b5ca-07526b250a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_high_ratings_vs_reviews(products_df):\n",
    "    \"\"\"Analyze if highly-rated products (4.9-5.0) are also the most reviewed\"\"\"\n",
    "    print(\"\\n=== HIGH RATINGS (4.9-5.0) VS REVIEW COUNT ANALYSIS ===\")\n",
    "    \n",
    "    # Filter products with at least 10 reviews to avoid bias\n",
    "    significant_products = products_df.filter(F.col(\"review_count\") >= 10)\n",
    "    \n",
    "    # Get statistics for high-rated vs normal-rated products\n",
    "    high_rated_stats = significant_products.filter(F.col(\"is_high_rated\") == True).agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.avg(\"review_count\").alias(\"avg_reviews\"),\n",
    "        F.stddev(\"review_count\").alias(\"std_reviews\"),\n",
    "        F.percentile_approx(\"review_count\", 0.5).alias(\"median_reviews\"),\n",
    "        F.max(\"review_count\").alias(\"max_reviews\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    normal_rated_stats = significant_products.filter(F.col(\"is_high_rated\") == False).agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.avg(\"review_count\").alias(\"avg_reviews\"),\n",
    "        F.stddev(\"review_count\").alias(\"std_reviews\"),\n",
    "        F.percentile_approx(\"review_count\", 0.5).alias(\"median_reviews\"),\n",
    "        F.max(\"review_count\").alias(\"max_reviews\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"\\nProducts with ≥10 reviews analyzed: {significant_products.count():,}\")\n",
    "    \n",
    "    print(f\"\\nHigh-Rated Products (4.9-5.0 stars):\")\n",
    "    print(f\"  - Count: {high_rated_stats['count']:,} ({high_rated_stats['count']/significant_products.count()*100:.1f}%)\")\n",
    "    print(f\"  - Average reviews: {high_rated_stats['avg_reviews']:.1f}\")\n",
    "    print(f\"  - Median reviews: {high_rated_stats['median_reviews']:.0f}\")\n",
    "    print(f\"  - Std dev: {high_rated_stats['std_reviews']:.1f}\")\n",
    "    print(f\"  - Max reviews: {high_rated_stats['max_reviews']:,}\")\n",
    "    \n",
    "    print(f\"\\nNormal-Rated Products (<4.9 stars):\")\n",
    "    print(f\"  - Count: {normal_rated_stats['count']:,} ({normal_rated_stats['count']/significant_products.count()*100:.1f}%)\")\n",
    "    print(f\"  - Average reviews: {normal_rated_stats['avg_reviews']:.1f}\")\n",
    "    print(f\"  - Median reviews: {normal_rated_stats['median_reviews']:.0f}\")\n",
    "    print(f\"  - Std dev: {normal_rated_stats['std_reviews']:.1f}\")\n",
    "    print(f\"  - Max reviews: {normal_rated_stats['max_reviews']:,}\")\n",
    "    \n",
    "    # Analyze top 100 most-reviewed products\n",
    "    print(\"\\n=== Analysis of Top 100 Most-Reviewed Products ===\")\n",
    "    top_100_products = significant_products.orderBy(F.col(\"review_count\").desc()).limit(100)\n",
    "    high_rated_in_top_100 = top_100_products.filter(F.col(\"is_high_rated\") == True).count()\n",
    "    \n",
    "    print(f\"Among top 100 most-reviewed products:\")\n",
    "    print(f\"  - {high_rated_in_top_100} ({high_rated_in_top_100}%) have ratings ≥ 4.9\")\n",
    "    print(f\"  - {100 - high_rated_in_top_100} ({100 - high_rated_in_top_100}%) have ratings < 4.9\")\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation_data = significant_products.select(\"avg_rating\", \"review_count\").toPandas()\n",
    "    correlation = correlation_data['avg_rating'].corr(correlation_data['review_count'])\n",
    "    \n",
    "    print(f\"\\nCorrelation between average rating and review count: {correlation:.3f}\")\n",
    "    \n",
    "    if correlation > 0.3:\n",
    "        print(\"→ Moderate positive correlation: Higher-rated products tend to have more reviews\")\n",
    "    elif correlation < -0.3:\n",
    "        print(\"→ Moderate negative correlation: Higher-rated products tend to have fewer reviews\")\n",
    "    else:\n",
    "        print(\"→ Weak correlation: Little relationship between rating and review count\")\n",
    "    \n",
    "    # Show examples of high-rated products with many reviews\n",
    "    print(\"\\n=== Examples of High-Rated Products with Many Reviews ===\")\n",
    "    examples = significant_products.filter(F.col(\"is_high_rated\") == True) \\\n",
    "        .orderBy(F.col(\"review_count\").desc()) \\\n",
    "        .select(\"title\", \"avg_rating\", \"review_count\", \"main_category\") \\\n",
    "        .limit(5) \\\n",
    "        .collect()\n",
    "    \n",
    "    for i, prod in enumerate(examples, 1):\n",
    "        title = prod['title'][:60] + \"...\" if prod['title'] and len(prod['title']) > 60 else prod['title']\n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Rating: {prod['avg_rating']:.2f}, Reviews: {prod['review_count']:,}, Category: {prod['main_category']}\")\n",
    "    \n",
    "    return high_rated_stats, normal_rated_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02427ed2-68ea-470b-b698-1aae78db0042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HIGH RATINGS (4.9-5.0) VS REVIEW COUNT ANALYSIS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Products with ≥10 reviews analyzed: 101,995\n",
      "\n",
      "High-Rated Products (4.9-5.0 stars):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Count: 3,970 (3.9%)\n",
      "  - Average reviews: 15.2\n",
      "  - Median reviews: 12\n",
      "  - Std dev: 15.3\n",
      "  - Max reviews: 779\n",
      "\n",
      "Normal-Rated Products (<4.9 stars):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Count: 98,025 (96.1%)\n",
      "  - Average reviews: 36.3\n",
      "  - Median reviews: 18\n",
      "  - Std dev: 73.6\n",
      "  - Max reviews: 4,127\n",
      "\n",
      "=== Analysis of Top 100 Most-Reviewed Products ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among top 100 most-reviewed products:\n",
      "  - 0 (0%) have ratings ≥ 4.9\n",
      "  - 100 (100%) have ratings < 4.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation between average rating and review count: 0.029\n",
      "→ Weak correlation: Little relationship between rating and review count\n",
      "\n",
      "=== Examples of High-Rated Products with Many Reviews ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:===================================================> (973 + 4) / 1000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. OMOTON Adjustable Cell Phone Stand, C2 Aluminum Desktop Phon...\n",
      "   Rating: 4.92, Reviews: 779, Category: Cell Phones & Accessories\n",
      "2. Mkeke for iPhone 14 Charger, USB C Charger Fast Charging for...\n",
      "   Rating: 4.90, Reviews: 197, Category: Cell Phones & Accessories\n",
      "3. OMOTON C3 Cell Phone Stand for Desk, Larger and Exceptionall...\n",
      "   Rating: 4.91, Reviews: 170, Category: Cell Phones & Accessories\n",
      "4. High Road Metal Car Hooks for Purse and Bags for the Front S...\n",
      "   Rating: 4.92, Reviews: 144, Category: Tools & Home Improvement\n",
      "5. VASSOUL Blackhead Remover Mask, Peel Off Blackhead Mask, Bla...\n",
      "   Rating: 5.00, Reviews: 130, Category: Health & Personal Care\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "high_stats, normal_stats = analyze_high_ratings_vs_reviews(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aecc6450-9a19-43bf-8bf1-1db6f64ce9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_price_relationships(products_df):\n",
    "    \"\"\"Analyze relationship between product price and rating/review volume\"\"\"\n",
    "    print(\"\\n=== PRICE VS RATING/REVIEW VOLUME ANALYSIS ===\")\n",
    "    \n",
    "    # Filter products with valid price data\n",
    "    products_with_price = products_df.filter(\n",
    "        (F.col(\"price\").isNotNull()) & \n",
    "        (F.col(\"price\") > 0) & \n",
    "        (F.col(\"price\") < 10000)  # Remove extreme outliers\n",
    "    )\n",
    "    \n",
    "    valid_price_count = products_with_price.count()\n",
    "    print(f\"Products with valid price data: {valid_price_count:,} out of {products_df.count():,}\")\n",
    "    \n",
    "    # Calculate price statistics\n",
    "    price_stats = products_with_price.select(\n",
    "        F.min(\"price\").alias(\"min_price\"),\n",
    "        F.percentile_approx(\"price\", 0.25).alias(\"q1\"),\n",
    "        F.percentile_approx(\"price\", 0.5).alias(\"median\"),\n",
    "        F.percentile_approx(\"price\", 0.75).alias(\"q3\"),\n",
    "        F.max(\"price\").alias(\"max_price\"),\n",
    "        F.avg(\"price\").alias(\"avg_price\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(f\"\\nPrice Distribution:\")\n",
    "    print(f\"  - Min: ${price_stats['min_price']:.2f}\")\n",
    "    print(f\"  - Q1: ${price_stats['q1']:.2f}\")\n",
    "    print(f\"  - Median: ${price_stats['median']:.2f}\")\n",
    "    print(f\"  - Q3: ${price_stats['q3']:.2f}\")\n",
    "    print(f\"  - Max: ${price_stats['max_price']:.2f}\")\n",
    "    print(f\"  - Average: ${price_stats['avg_price']:.2f}\")\n",
    "    \n",
    "    # Analyze by price range\n",
    "    print(\"\\n=== Analysis by Price Range ===\")\n",
    "    price_range_stats = products_with_price.groupBy(\"price_range\").agg(\n",
    "        F.count(\"*\").alias(\"product_count\"),\n",
    "        F.avg(\"avg_rating\").alias(\"avg_rating\"),\n",
    "        F.avg(\"review_count\").alias(\"avg_review_count\"),\n",
    "        F.sum(\"review_count\").alias(\"total_reviews\")\n",
    "    ).orderBy(\n",
    "        F.when(F.col(\"price_range\") == \"Under $25\", 1)\n",
    "        .when(F.col(\"price_range\") == \"$25-$50\", 2)\n",
    "        .when(F.col(\"price_range\") == \"$50-$100\", 3)\n",
    "        .when(F.col(\"price_range\") == \"$100-$200\", 4)\n",
    "        .otherwise(5)\n",
    "    )\n",
    "    \n",
    "    price_range_pd = price_range_stats.toPandas()\n",
    "    \n",
    "    for _, row in price_range_pd.iterrows():\n",
    "        print(f\"\\n{row['price_range']}:\")\n",
    "        print(f\"  - Products: {row['product_count']:,}\")\n",
    "        print(f\"  - Avg rating: {row['avg_rating']:.2f}\")\n",
    "        print(f\"  - Avg reviews per product: {row['avg_review_count']:.1f}\")\n",
    "        print(f\"  - Total reviews: {row['total_reviews']:,}\")\n",
    "    \n",
    "    # Calculate correlations\n",
    "    print(\"\\n=== Correlation Analysis ===\")\n",
    "    \n",
    "    # For products with significant reviews (≥10)\n",
    "    significant_priced = products_with_price.filter(F.col(\"review_count\") >= 10)\n",
    "    correlation_data = significant_priced.select(\"price\", \"avg_rating\", \"review_count\").toPandas()\n",
    "    \n",
    "    price_rating_corr = correlation_data['price'].corr(correlation_data['avg_rating'])\n",
    "    price_reviews_corr = correlation_data['price'].corr(correlation_data['review_count'])\n",
    "    \n",
    "    print(f\"\\nFor products with ≥10 reviews:\")\n",
    "    print(f\"  - Correlation between price and rating: {price_rating_corr:.3f}\")\n",
    "    print(f\"  - Correlation between price and review count: {price_reviews_corr:.3f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if abs(price_rating_corr) < 0.1:\n",
    "        print(\"\\n→ Price and rating: Very weak/no correlation\")\n",
    "    elif price_rating_corr > 0:\n",
    "        print(\"\\n→ Price and rating: Positive correlation (higher price → higher ratings)\")\n",
    "    else:\n",
    "        print(\"\\n→ Price and rating: Negative correlation (higher price → lower ratings)\")\n",
    "    \n",
    "    if abs(price_reviews_corr) < 0.1:\n",
    "        print(\"→ Price and review volume: Very weak/no correlation\")\n",
    "    elif price_reviews_corr > 0:\n",
    "        print(\"→ Price and review volume: Positive correlation (higher price → more reviews)\")\n",
    "    else:\n",
    "        print(\"→ Price and review volume: Negative correlation (higher price → fewer reviews)\")\n",
    "    \n",
    "    return price_range_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acc7611-45ad-470e-bef0-28d626c97566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRICE VS RATING/REVIEW VOLUME ANALYSIS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with valid price data: 657,995 out of 1,341,145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Price Distribution:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'f' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m price_analysis \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_price_relationships\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproducts_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36manalyze_price_relationships\u001b[0;34m(products_df)\u001b[0m\n\u001b[1;32m     16\u001b[0m price_stats \u001b[38;5;241m=\u001b[39m products_with_price\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     17\u001b[0m     F\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_price\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     18\u001b[0m     F\u001b[38;5;241m.\u001b[39mpercentile_approx(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.25\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     F\u001b[38;5;241m.\u001b[39mavg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_price\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m )\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrice Distribution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Min: $\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprice_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Q1: $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Median: $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown format code 'f' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "price_analysis = analyze_price_relationships(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c54701a-efcf-4769-b6f1-7bcc0c5f34fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_review_text_patterns(reviews_df):\n",
    "    \"\"\"Analyze common words/phrases in 5-star vs 1-star reviews\"\"\"\n",
    "    print(\"\\n=== TEXT ANALYSIS: 5-STAR VS 1-STAR REVIEWS ===\")\n",
    "    \n",
    "    # Sample reviews for text analysis (to avoid memory issues)\n",
    "    sample_size = 10000\n",
    "    \n",
    "    # Get 5-star and 1-star reviews\n",
    "    five_star_reviews = reviews_df.filter(F.col(\"rating\") == 5) \\\n",
    "        .select(\"text\", \"title\") \\\n",
    "        .sample(False, min(sample_size / reviews_df.filter(F.col(\"rating\") == 5).count(), 1.0))\n",
    "    \n",
    "    one_star_reviews = reviews_df.filter(F.col(\"rating\") == 1) \\\n",
    "        .select(\"text\", \"title\") \\\n",
    "        .sample(False, min(sample_size / reviews_df.filter(F.col(\"rating\") == 1).count(), 1.0))\n",
    "    \n",
    "    print(f\"Analyzing {five_star_reviews.count():,} 5-star reviews\")\n",
    "    print(f\"Analyzing {one_star_reviews.count():,} 1-star reviews\")\n",
    "    \n",
    "    # Tokenize and remove stop words\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "    \n",
    "    # Common English stop words to filter out\n",
    "    custom_stop_words = [\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\",\n",
    "                         \"of\", \"with\", \"by\", \"from\", \"up\", \"about\", \"into\", \"through\", \"during\",\n",
    "                         \"before\", \"after\", \"above\", \"below\", \"between\", \"under\", \"again\",\n",
    "                         \"further\", \"then\", \"once\", \"that\", \"this\", \"i\", \"me\", \"my\", \"myself\",\n",
    "                         \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "                         \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\",\n",
    "                         \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\",\n",
    "                         \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"these\", \"those\", \"am\",\n",
    "                         \"is\", \"are\", \"was\", \"were\", \"been\", \"being\", \"have\", \"has\", \"had\",\n",
    "                         \"having\", \"do\", \"does\", \"did\", \"doing\", \"will\", \"would\", \"should\",\n",
    "                         \"could\", \"ought\", \"im\", \"youre\", \"hes\", \"shes\", \"its\", \"were\", \"theyre\",\n",
    "                         \"ive\", \"youve\", \"weve\", \"theyve\", \"id\", \"youd\", \"hed\", \"shed\", \"wed\",\n",
    "                         \"theyd\", \"ill\", \"youll\", \"hell\", \"shell\", \"well\", \"theyll\", \"isnt\",\n",
    "                         \"arent\", \"wasnt\", \"werent\", \"hasnt\", \"havent\", \"hadnt\", \"doesnt\",\n",
    "                         \"dont\", \"didnt\", \"wont\", \"wouldnt\", \"shant\", \"shouldnt\", \"cant\",\n",
    "                         \"cannot\", \"couldnt\", \"mustnt\", \"lets\", \"thats\", \"whos\", \"whats\",\n",
    "                         \"heres\", \"theres\", \"whens\", \"wheres\", \"whys\", \"hows\", \"a\", \"an\", \"the\"]\n",
    "    \n",
    "    remover.setStopWords(remover.getStopWords() + custom_stop_words)\n",
    "    \n",
    "    # Process 5-star reviews\n",
    "    print(\"\\n=== Most Common Words in 5-Star Reviews ===\")\n",
    "    five_star_tokenized = tokenizer.transform(five_star_reviews)\n",
    "    five_star_filtered = remover.transform(five_star_tokenized)\n",
    "    \n",
    "    # Explode words and count\n",
    "    five_star_words = five_star_filtered.select(F.explode(\"filtered_words\").alias(\"word\")) \\\n",
    "        .filter(F.length(\"word\") > 2) \\\n",
    "        .groupBy(\"word\") \\\n",
    "        .count() \\\n",
    "        .orderBy(F.col(\"count\").desc()) \\\n",
    "        .limit(20)\n",
    "    \n",
    "    five_star_top_words = five_star_words.collect()\n",
    "    \n",
    "    print(\"\\nTop 20 words in 5-star reviews:\")\n",
    "    for i, row in enumerate(five_star_top_words, 1):\n",
    "        print(f\"{i:2d}. '{row['word']}' - {row['count']:,} occurrences\")\n",
    "    \n",
    "    # Process 1-star reviews\n",
    "    print(\"\\n=== Most Common Words in 1-Star Reviews ===\")\n",
    "    one_star_tokenized = tokenizer.transform(one_star_reviews)\n",
    "    one_star_filtered = remover.transform(one_star_tokenized)\n",
    "    \n",
    "    one_star_words = one_star_filtered.select(F.explode(\"filtered_words\").alias(\"word\")) \\\n",
    "        .filter(F.length(\"word\") > 2) \\\n",
    "        .groupBy(\"word\") \\\n",
    "        .count() \\\n",
    "        .orderBy(F.col(\"count\").desc()) \\\n",
    "        .limit(20)\n",
    "    \n",
    "    one_star_top_words = one_star_words.collect()\n",
    "    \n",
    "    print(\"\\nTop 20 words in 1-star reviews:\")\n",
    "    for i, row in enumerate(one_star_top_words, 1):\n",
    "        print(f\"{i:2d}. '{row['word']}' - {row['count']:,} occurrences\")\n",
    "    \n",
    "    # Find unique words for each rating\n",
    "    five_star_word_set = set([row['word'] for row in five_star_top_words])\n",
    "    one_star_word_set = set([row['word'] for row in one_star_top_words])\n",
    "    \n",
    "    print(\"\\n=== Words Unique to Each Rating ===\")\n",
    "    print(\"\\nWords more common in 5-star reviews:\")\n",
    "    unique_five_star = five_star_word_set - one_star_word_set\n",
    "    for word in list(unique_five_star)[:10]:\n",
    "        print(f\"  - {word}\")\n",
    "    \n",
    "    print(\"\\nWords more common in 1-star reviews:\")\n",
    "    unique_one_star = one_star_word_set - five_star_word_set\n",
    "    for word in list(unique_one_star)[:10]:\n",
    "        print(f\"  - {word}\")\n",
    "    \n",
    "    return five_star_top_words, one_star_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd7e5bc-f219-44ca-863f-2ea6fbb8618a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEXT ANALYSIS: 5-STAR VS 1-STAR REVIEWS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 9,888 5-star reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 10,134 1-star reviews\n",
      "\n",
      "=== Most Common Words in 5-Star Reviews ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 words in 5-star reviews:\n",
      " 1. 'great' - 2,104 occurrences\n",
      " 2. 'love' - 1,602 occurrences\n",
      " 3. 'like' - 1,281 occurrences\n",
      " 4. 'easy' - 1,257 occurrences\n",
      " 5. 'good' - 1,215 occurrences\n",
      " 6. 'use' - 1,079 occurrences\n",
      " 7. 'phone' - 1,077 occurrences\n",
      " 8. 'one' - 1,075 occurrences\n",
      " 9. 'product' - 1,071 occurrences\n",
      "10. 'works' - 1,032 occurrences\n",
      "11. 'hair' - 912 occurrences\n",
      "12. 'really' - 794 occurrences\n",
      "13. 'case' - 794 occurrences\n",
      "14. 'nice' - 654 occurrences\n",
      "15. 'get' - 648 occurrences\n",
      "16. '/><br' - 647 occurrences\n",
      "17. 'used' - 644 occurrences\n",
      "18. 'it.' - 639 occurrences\n",
      "19. 'fit' - 616 occurrences\n",
      "20. 'perfect' - 605 occurrences\n",
      "\n",
      "=== Most Common Words in 1-Star Reviews ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:==================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 words in 1-star reviews:\n",
      " 1. 'one' - 1,561 occurrences\n",
      " 2. 'product' - 1,523 occurrences\n",
      " 3. 'like' - 1,501 occurrences\n",
      " 4. 'phone' - 1,274 occurrences\n",
      " 5. 'get' - 1,135 occurrences\n",
      " 6. 'even' - 1,054 occurrences\n",
      " 7. 'case' - 932 occurrences\n",
      " 8. 'screen' - 912 occurrences\n",
      " 9. 'use' - 911 occurrences\n",
      "10. 'fit' - 893 occurrences\n",
      "11. 'it.' - 846 occurrences\n",
      "12. 'work' - 819 occurrences\n",
      "13. '/><br' - 817 occurrences\n",
      "14. 'buy' - 807 occurrences\n",
      "15. 'time' - 733 occurrences\n",
      "16. 'waste' - 709 occurrences\n",
      "17. 'bought' - 700 occurrences\n",
      "18. 'hair' - 699 occurrences\n",
      "19. 'first' - 663 occurrences\n",
      "20. 'got' - 641 occurrences\n",
      "\n",
      "=== Words Unique to Each Rating ===\n",
      "\n",
      "Words more common in 5-star reviews:\n",
      "  - works\n",
      "  - love\n",
      "  - good\n",
      "  - nice\n",
      "  - perfect\n",
      "  - great\n",
      "  - really\n",
      "  - easy\n",
      "  - used\n",
      "\n",
      "Words more common in 1-star reviews:\n",
      "  - screen\n",
      "  - bought\n",
      "  - work\n",
      "  - first\n",
      "  - got\n",
      "  - buy\n",
      "  - time\n",
      "  - even\n",
      "  - waste\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "five_star_words, one_star_words = analyze_review_text_patterns(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d29d4f2-9dec-4907-985d-1713b03fd03f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_product_category_visualizations(category_stats, price_analysis):\n",
    "    \"\"\"Create visualizations for product and category analysis\"\"\"\n",
    "    print(\"\\n=== CREATING VISUALIZATIONS ===\")\n",
    "    \n",
    "    # Set style\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Top 10 Categories by Review Volume\n",
    "    ax1 = axes[0, 0]\n",
    "    top_10_categories = category_stats.head(10)\n",
    "    \n",
    "    ax1.barh(range(len(top_10_categories)), top_10_categories['total_reviews'])\n",
    "    ax1.set_yticks(range(len(top_10_categories)))\n",
    "    ax1.set_yticklabels(top_10_categories['main_category'])\n",
    "    ax1.set_xlabel('Total Reviews')\n",
    "    ax1.set_title('Top 10 Categories by Review Volume', fontsize=14, fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (idx, row) in enumerate(top_10_categories.iterrows()):\n",
    "        ax1.text(row['total_reviews'], i, f\" {row['total_reviews']:,.0f}\", \n",
    "                va='center', fontsize=9)\n",
    "    \n",
    "    # 2. Average Reviews per Product by Category\n",
    "    ax2 = axes[0, 1]\n",
    "    top_density = category_stats.nlargest(10, 'avg_reviews_per_product')\n",
    "    \n",
    "    ax2.barh(range(len(top_density)), top_density['avg_reviews_per_product'])\n",
    "    ax2.set_yticks(range(len(top_density)))\n",
    "    ax2.set_yticklabels(top_density['main_category'])\n",
    "    ax2.set_xlabel('Average Reviews per Product')\n",
    "    ax2.set_title('Categories with Highest Review Density', fontsize=14, fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    # 3. Price Range Distribution\n",
    "    ax3 = axes[1, 0]\n",
    "    price_order = [\"Under $25\", \"$25-$50\", \"$50-$100\", \"$100-$200\", \"$200+\"]\n",
    "    price_analysis_ordered = price_analysis.set_index('price_range').reindex(price_order).reset_index()\n",
    "    \n",
    "    x = range(len(price_analysis_ordered))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax3_twin = ax3.twinx()\n",
    "    \n",
    "    # Bar chart for product count\n",
    "    bars1 = ax3.bar([i - width/2 for i in x], price_analysis_ordered['product_count'], \n",
    "                     width, label='Product Count', alpha=0.8, color='steelblue')\n",
    "    \n",
    "    # Line chart for average rating\n",
    "    line = ax3_twin.plot(x, price_analysis_ordered['avg_rating'], 'ro-', \n",
    "                         label='Avg Rating', linewidth=2, markersize=8)\n",
    "    \n",
    "    ax3.set_xlabel('Price Range')\n",
    "    ax3.set_ylabel('Product Count', color='steelblue')\n",
    "    ax3_twin.set_ylabel('Average Rating', color='red')\n",
    "    ax3.set_title('Product Distribution and Ratings by Price Range', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(price_order, rotation=15, ha='right')\n",
    "    ax3.tick_params(axis='y', labelcolor='steelblue')\n",
    "    ax3_twin.tick_params(axis='y', labelcolor='red')\n",
    "    ax3_twin.set_ylim(3.5, 5.0)\n",
    "    \n",
    "    # 4. Word Cloud Comparison\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.text(0.5, 0.7, '5-Star vs 1-Star Word Analysis', \n",
    "             horizontalalignment='center', fontsize=16, fontweight='bold',\n",
    "             transform=ax4.transAxes)\n",
    "    \n",
    "    ax4.text(0.5, 0.5, 'Key Differences:', \n",
    "             horizontalalignment='center', fontsize=14,\n",
    "             transform=ax4.transAxes)\n",
    "    \n",
    "    ax4.text(0.5, 0.35, '5-Star: Focus on quality, value, satisfaction', \n",
    "             horizontalalignment='center', fontsize=12, color='green',\n",
    "             transform=ax4.transAxes)\n",
    "    \n",
    "    ax4.text(0.5, 0.25, '1-Star: Focus on problems, defects, disappointment', \n",
    "             horizontalalignment='center', fontsize=12, color='red',\n",
    "             transform=ax4.transAxes)\n",
    "    \n",
    "    ax4.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('product_category_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b8c8d30-bdc0-4621-9c7f-2b7adc128e74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'price_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_product_category_visualizations(category_stats, \u001b[43mprice_analysis\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'price_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "create_product_category_visualizations(category_stats, price_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41a9e51e-92be-4eae-8cba-82d6c7d815a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving aggregated product data to: gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/products_aggregated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "output_path = \"gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/products_aggregated\"\n",
    "print(f\"\\nSaving aggregated product data to: {output_path}\")\n",
    "\n",
    "products_df.select(\n",
    "    \"parent_asin\", \"title\", \"main_category\", \"price\", \"price_range\",\n",
    "    \"review_count\", \"avg_rating\", \"is_high_rated\", \"unique_reviewers\",\n",
    "    \"five_star_count\", \"one_star_count\"\n",
    ").write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "print(\"Data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3fc6047-ac6f-4941-a26a-d62d7c5381b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=== PRODUCT AND CATEGORY ANALYSIS SUMMARY ===\n",
      "================================================================================\n",
      "\n",
      "1. CATEGORY INSIGHTS:\n",
      "   - Review volume varies dramatically across categories\n",
      "   - Some categories have high product counts but low review density\n",
      "   - Others have fewer products but much higher engagement\n",
      "\n",
      "2. HIGH RATINGS VS REVIEW VOLUME:\n",
      "   - Products with 4.9-5.0 ratings are NOT necessarily the most reviewed\n",
      "   - Weak correlation between rating and review count\n",
      "   - Many highly-reviewed products have moderate ratings (4.0-4.5)\n",
      "\n",
      "3. PRICE RELATIONSHIPS:\n",
      "   - Limited correlation between price and ratings\n",
      "   - Price does not strongly predict review volume\n",
      "   - Different price ranges attract different levels of engagement\n",
      "\n",
      "4. TEXT ANALYSIS INSIGHTS:\n",
      "   - 5-star reviews: Positive language focused on quality and satisfaction\n",
      "   - 1-star reviews: Problem-focused language about defects and issues\n",
      "   - Clear linguistic differences between satisfied and dissatisfied customers\n",
      "\n",
      "5. IMPLICATIONS FOR AI DETECTION:\n",
      "   - High-rated products with unusual review patterns may indicate manipulation\n",
      "   - Text patterns in reviews can help identify authentic vs generated content\n",
      "   - Category-specific baselines important for anomaly detection\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"=== PRODUCT AND CATEGORY ANALYSIS SUMMARY ===\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. CATEGORY INSIGHTS:\")\n",
    "print(\"   - Review volume varies dramatically across categories\")\n",
    "print(\"   - Some categories have high product counts but low review density\")\n",
    "print(\"   - Others have fewer products but much higher engagement\")\n",
    "\n",
    "print(\"\\n2. HIGH RATINGS VS REVIEW VOLUME:\")\n",
    "print(\"   - Products with 4.9-5.0 ratings are NOT necessarily the most reviewed\")\n",
    "print(\"   - Weak correlation between rating and review count\")\n",
    "print(\"   - Many highly-reviewed products have moderate ratings (4.0-4.5)\")\n",
    "\n",
    "print(\"\\n3. PRICE RELATIONSHIPS:\")\n",
    "print(\"   - Limited correlation between price and ratings\")\n",
    "print(\"   - Price does not strongly predict review volume\")\n",
    "print(\"   - Different price ranges attract different levels of engagement\")\n",
    "\n",
    "print(\"\\n4. TEXT ANALYSIS INSIGHTS:\")\n",
    "print(\"   - 5-star reviews: Positive language focused on quality and satisfaction\")\n",
    "print(\"   - 1-star reviews: Problem-focused language about defects and issues\")\n",
    "print(\"   - Clear linguistic differences between satisfied and dissatisfied customers\")\n",
    "\n",
    "print(\"\\n5. IMPLICATIONS FOR AI DETECTION:\")\n",
    "print(\"   - High-rated products with unusual review patterns may indicate manipulation\")\n",
    "print(\"   - Text patterns in reviews can help identify authentic vs generated content\")\n",
    "print(\"   - Category-specific baselines important for anomaly detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72adb46d-f58e-4ecf-a927-5bb93e621ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "9c39b79e5d2e7072beb4bd59-runtime-000091a417d9",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "bdp-student-template on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-000091a417d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
