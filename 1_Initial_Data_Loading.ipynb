{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df180e90-bfd4-4368-9016-5352c659c456",
   "metadata": {},
   "source": [
    "# Big Data and Cloud Computing - Final Project\n",
    "\n",
    "## Initial Data Loading\n",
    "\n",
    "### Author:\n",
    "Alen Pavlovic\n",
    "\n",
    "The University of Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87a0c2c-50bc-4ec8-9e28-84d0aef3cbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74288c85-6e2f-4560-b3aa-dad157d6573e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77db2c9-487f-418b-b687-c913d6acff2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display settings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2623ec1c-fb0b-4eb5-92be-d705185f564d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enable eager evaluation\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2ed14b-7a15-43bc-b2cd-269ae2ecefc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCS path to the data\n",
    "gcs_folder = 'gs://msca-bdp-data-open/final_project_reviews'\n",
    "\n",
    "# Intermediate storage bucket - apavlovic\n",
    "intermediate_bucket = 'gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d5f7bb-df7e-4788-9c5e-67155bcbc054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. CHECK DATA SIZE IN GCS\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def check_folder_size(folder_path):\n",
    "    \"\"\"Check the size of a GCS folder\"\"\"\n",
    "    cmd = f'gsutil du -s -h {folder_path}'\n",
    "    \n",
    "    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "    for line in p.stdout.readlines():\n",
    "        print(f'Total directory size: {line}')\n",
    "    \n",
    "    retval = p.wait()  # Wait for child process to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b6c4c7-92be-41f8-abf8-1e29eeb52975",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data size in GCS bucket...\n",
      "Total directory size: 75.75 GiB    gs://msca-bdp-data-open/final_project_reviews\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking data size in GCS bucket...\")\n",
    "check_folder_size(gcs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb4ca64-b370-441c-aee6-c3afbe768e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 2. BASIC DATA LOADING\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def load_reviews_sample(sample_fraction=0.001):\n",
    "    \"\"\"Load a small sample of the reviews data for exploration\"\"\"\n",
    "    print(f\"Loading {sample_fraction*100}% sample of reviews data...\")\n",
    "    \n",
    "    # Read the entire reviews dataset\n",
    "    df_reviews = spark.read.parquet(os.path.join(gcs_folder, 'reviews_parquet'))\n",
    "    \n",
    "    # Take a sample for exploration\n",
    "    if sample_fraction < 1.0:\n",
    "        df_reviews_sample = df_reviews.sample(fraction=sample_fraction, seed=42)\n",
    "        print(f\"Sample size: {df_reviews_sample.count():,} records\")\n",
    "        return df_reviews_sample\n",
    "    else:\n",
    "        print(f\"Full dataset size: {df_reviews.count():,} records\")\n",
    "        return df_reviews\n",
    "    \n",
    "def load_meta_sample(sample_fraction=0.01):\n",
    "    \"\"\"Load a small sample of the metadata for exploration\"\"\"\n",
    "    print(f\"Loading {sample_fraction*100}% sample of metadata...\")\n",
    "    \n",
    "    # Read the entire metadata dataset\n",
    "    df_meta = spark.read.parquet(os.path.join(gcs_folder, 'meta_parquet'))\n",
    "    \n",
    "    # Take a sample for exploration\n",
    "    if sample_fraction < 1.0:\n",
    "        df_meta_sample = df_meta.sample(fraction=sample_fraction, seed=42)\n",
    "        print(f\"Sample size: {df_meta_sample.count():,} records\")\n",
    "        return df_meta_sample\n",
    "    else:\n",
    "        print(f\"Full dataset size: {df_meta.count():,} records\")\n",
    "        return df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76339822-edb0-466e-879f-1e64739672ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 0.1% sample of reviews data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 64,380 records\n",
      "Loading 1.0% sample of metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:========================================>                 (9 + 4) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 43,305 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews_sample = load_reviews_sample()\n",
    "meta_sample = load_meta_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c66a69-97e1-44cc-b387-48dbab5f87c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reviews_sample\n",
    "#meta_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d2c7af-dbc5-484e-8ecf-b03399535c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reviews Data Schema ---\n",
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful_vote: long (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- verified_purchase: boolean (nullable = true)\n",
      "\n",
      "\n",
      "--- Metadata Schema ---\n",
      "root\n",
      " |-- author: struct (nullable = true)\n",
      " |    |-- about: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- avatar: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- average_rating: double (nullable = true)\n",
      " |-- bought_together: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- rating_number: long (nullable = true)\n",
      " |-- store: string (nullable = true)\n",
      " |-- subtitle: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. EXPLORE DATA STRUCTURE\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Reviews Data Schema ---\")\n",
    "reviews_sample.printSchema()\n",
    "\n",
    "print(\"\\n--- Metadata Schema ---\")\n",
    "meta_sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493b83fd-8639-4b97-a6eb-550ce7cdaf5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample Reviews Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+------+--------------------+-------------+--------------------+--------------------+-----------------+\n",
      "|      asin|helpful_vote|parent_asin|rating|                text|    timestamp|               title|             user_id|verified_purchase|\n",
      "+----------+------------+-----------+------+--------------------+-------------+--------------------+--------------------+-----------------+\n",
      "|B09CBNY1SB|           2| B09CBNY1SB|   3.0|[[VIDEOID:3f9ba83...|1658512339071|           It's OkðŸ§¡|AGCFOUKPOYBQJFN4F...|            false|\n",
      "|B00I3N6AM8|           0| B00I3N6AM8|   3.0|I have received t...|1461374668000|Reasonable Price ...|AFDOQTCP7SI36QPDC...|            false|\n",
      "|B01KI40G3I|           0| B01LX6I5X0|   5.0|           Love it!!|1523381799799|          Five Stars|AEKIAS5INUOBSFLUH...|             true|\n",
      "|B0058K1MJ0|           4| B0058K1MJ0|   5.0|I don't understan...|1621392460645|Why are they do e...|AE3G4X4NUNDMZESTV...|            false|\n",
      "|B08R7P97F6|           0| B08R7P97F6|   5.0|Not only does thi...|1659054380866|            Amazing!|AEJ5BJJ27OQTMKWEJ...|             true|\n",
      "+----------+------------+-----------+------+--------------------+-------------+--------------------+--------------------+-----------------+\n",
      "\n",
      "\n",
      "--- Sample Metadata ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------+--------------------+--------------------+--------------+-----------+-----+-------------+--------------+--------+--------------------+\n",
      "|author|average_rating|bought_together|          categories|         description| main_category|parent_asin|price|rating_number|         store|subtitle|               title|\n",
      "+------+--------------+---------------+--------------------+--------------------+--------------+-----------+-----+-------------+--------------+--------+--------------------+\n",
      "|  NULL|           4.4|           NULL|[Beauty & Persona...|[Wow your friends...|    All Beauty| B0C1P4S34H| 5.99|           16|    Fawalyanle|    NULL|Personalized Temp...|\n",
      "|  NULL|           4.1|           NULL|[Beauty & Persona...|[The Healthy You ...|          NULL| B08769W6BC| NULL|           31|   Healthy You|    NULL|Massage Face Pill...|\n",
      "|  NULL|           4.3|           NULL|[Beauty & Persona...|[One Smart Cookie...|          NULL| B06X16GZCB| NULL|            7|Perfectly Posh|    NULL|Perfectly Posh On...|\n",
      "|  NULL|           4.6|           NULL|[Beauty & Persona...|                  []|Premium Beauty| B08V53LL23| NULL|           22|          NULL|    NULL|Dose of Colors Li...|\n",
      "|  NULL|           5.0|           NULL|[Automotive, Exte...|        [BRAND NEW!]|    Automotive| B00OBT9X04| 4.99|            1|   JS Artworks|    NULL|Caution Student D...|\n",
      "+------+--------------+---------------+--------------------+--------------------+--------------+-----------+-----+-------------+--------------+--------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print few rows\n",
    "print(\"\\n--- Sample Reviews Data ---\")\n",
    "reviews_sample.limit(5).show()\n",
    "\n",
    "print(\"\\n--- Sample Metadata ---\")\n",
    "meta_sample.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe236e54-615e-4fbb-8fa0-ef0d2c3093c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values in Reviews ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'asin': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'helpful_vote': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'parent_asin': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'rating': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'text': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'timestamp': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'title': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'user_id': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:======================================================>(99 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'verified_purchase': 0 nulls (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 4. BASIC DATA EXPLORATION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Missing Values in Reviews ---\")\n",
    "for col in reviews_sample.columns:\n",
    "    null_count = reviews_sample.filter(F.col(col).isNull()).count()\n",
    "    total_count = reviews_sample.count()\n",
    "    print(f\"Column '{col}': {null_count:,} nulls ({null_count/total_count*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58079b9d-0bda-457d-b834-bc6717159fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Review Date Distribution ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:======================================================>(99 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2004|    1|\n",
      "|2005|   11|\n",
      "|2006|    6|\n",
      "|2007|   11|\n",
      "|2008|   37|\n",
      "|2009|   60|\n",
      "|2010|  105|\n",
      "|2011|  232|\n",
      "|2012|  529|\n",
      "|2013| 1486|\n",
      "|2014| 2545|\n",
      "|2015| 4157|\n",
      "|2016| 4946|\n",
      "|2017| 5164|\n",
      "|2018| 5840|\n",
      "|2019| 8162|\n",
      "|2020| 8875|\n",
      "|2021| 9447|\n",
      "|2022| 8938|\n",
      "|2023| 3828|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Review Date Distribution ---\")\n",
    "reviews_sample_with_date = reviews_sample.withColumn(\n",
    "    \"review_date\", \n",
    "    F.to_date(F.from_unixtime(F.col(\"timestamp\") / 1000))\n",
    ")\n",
    "\n",
    "date_dist = reviews_sample_with_date.groupBy(\n",
    "    F.year(\"review_date\").alias(\"year\")\n",
    ").count().orderBy(\"year\")\n",
    "\n",
    "date_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c2046dd-1b83-4b5a-a171-5ee4546555ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 5. CREATE HELPER FUNCTIONS FOR FULL ANALYSIS\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def create_intermediate_folder():\n",
    "    \"\"\"Create intermediate folder if it doesn't exist\"\"\"\n",
    "    cmd = f'gsutil ls {intermediate_bucket}'\n",
    "    try:\n",
    "        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        output, error = p.communicate()\n",
    "        \n",
    "        if p.returncode != 0:\n",
    "            # Bucket/folder doesn't exist, create it\n",
    "            cmd = f'gsutil mkdir -p {intermediate_bucket}'\n",
    "            subprocess.run(cmd, shell=True)\n",
    "            print(f\"Created intermediate bucket: {intermediate_bucket}\")\n",
    "        else:\n",
    "            print(f\"Intermediate bucket already exists: {intermediate_bucket}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking/creating bucket: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154a0c5f-6c0a-4815-a3bd-ad3e53c2f2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_full_reviews_data():\n",
    "    \"\"\"Process the full reviews dataset with basic transformations\"\"\"\n",
    "    # Load full reviews dataset\n",
    "    df_reviews = spark.read.parquet(os.path.join(gcs_folder, 'reviews_parquet'))\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    df_reviews_processed = df_reviews.withColumn(\n",
    "        \"review_date\", \n",
    "        F.to_date(F.from_unixtime(F.col(\"timestamp\") / 1000))\n",
    "    )\n",
    "    \n",
    "    # Add year and month columns for time analysis\n",
    "    df_reviews_processed = df_reviews_processed.withColumn(\"review_year\", F.year(\"review_date\"))\n",
    "    df_reviews_processed = df_reviews_processed.withColumn(\"review_month\", F.month(\"review_date\"))\n",
    "    \n",
    "    # Filter out records with null essential fields\n",
    "    df_reviews_clean = df_reviews_processed.filter(\n",
    "        (F.col(\"asin\").isNotNull()) & \n",
    "        (F.col(\"user_id\").isNotNull()) &\n",
    "        (F.col(\"review_date\").isNotNull())\n",
    "    )\n",
    "    \n",
    "    # Save processed data\n",
    "    df_reviews_clean.write.mode(\"overwrite\").parquet(f\"{intermediate_bucket}/reviews_processed\")\n",
    "    print(f\"Processed {df_reviews_clean.count():,} review records and saved to {intermediate_bucket}/reviews_processed\")\n",
    "    \n",
    "    return df_reviews_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db53dd2a-8c20-4be0-ab62-3e270f65efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_reviews_data_v2():\n",
    "    \"\"\"Enhanced version with better partitioning\"\"\"\n",
    "    # Load full reviews dataset\n",
    "    df_reviews = spark.read.parquet(os.path.join(gcs_folder, 'reviews_parquet'))\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    df_reviews_processed = df_reviews.withColumn(\n",
    "        \"timestamp\", F.to_timestamp(F.col(\"timestamp\"))\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"timestamp\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"timestamp\")\n",
    "    )\n",
    "    \n",
    "    # Filter out nulls\n",
    "    df_reviews_clean = df_reviews_processed.filter(\n",
    "        (F.col(\"parent_asin\").isNotNull()) & \n",
    "        (F.col(\"user_id\").isNotNull()) &\n",
    "        (F.col(\"timestamp\").isNotNull())\n",
    "    )\n",
    "    \n",
    "    # Repartition by year for better downstream processing\n",
    "    df_reviews_clean = df_reviews_clean.repartition(200, \"year\")\n",
    "    \n",
    "    # Save with partitioning\n",
    "    df_reviews_clean.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\") \\\n",
    "        .parquet(f\"{intermediate_bucket}/reviews_processed_v2\")\n",
    "    \n",
    "    print(f\"Processed {df_reviews_clean.count():,} review records\")\n",
    "    print(f\"Saved to {intermediate_bucket}/reviews_processed_v2 partitioned by year\")\n",
    "    \n",
    "    return df_reviews_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e787c8a-4ed8-43a9-b9aa-953bc31d0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_statistics():\n",
    "    \"\"\"Create summary statistics for processed data\"\"\"\n",
    "    print(\"Creating summary statistics...\")\n",
    "    \n",
    "    # Load processed data\n",
    "    reviews_df = spark.read.parquet(f\"{intermediate_bucket}/reviews_processed\")\n",
    "    meta_df = spark.read.parquet(f\"{intermediate_bucket}/meta_processed\")\n",
    "    \n",
    "    # Get basic counts\n",
    "    review_count = reviews_df.count()\n",
    "    meta_count = meta_df.count()\n",
    "    \n",
    "    # Get date range - convert timestamp to readable format\n",
    "    date_stats = reviews_df.select(\n",
    "        F.from_unixtime(F.col(\"timestamp\")/1000).cast(\"date\").alias(\"earliest_review\"),\n",
    "        F.from_unixtime(F.col(\"timestamp\")/1000).cast(\"date\").alias(\"latest_review\")\n",
    "    ).agg(\n",
    "        F.min(\"earliest_review\").alias(\"earliest_review\"),\n",
    "        F.max(\"latest_review\").alias(\"latest_review\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    # Get category distribution\n",
    "    category_counts = meta_df.groupBy(\"main_category\").count().orderBy(F.desc(\"count\"))\n",
    "    \n",
    "    # Get unique reviewers and products\n",
    "    unique_reviewers = reviews_df.select(\"user_id\").distinct().count()\n",
    "    unique_products = reviews_df.select(\"parent_asin\").distinct().count()\n",
    "    \n",
    "    # Create summary dict\n",
    "    summary = {\n",
    "        \"total_reviews\": review_count,\n",
    "        \"total_products\": meta_count,\n",
    "        \"unique_reviewers\": unique_reviewers,\n",
    "        \"unique_products\": unique_products,\n",
    "        \"date_range\": f\"{date_stats['earliest_review']} to {date_stats['latest_review']}\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== DATA SUMMARY ===\")\n",
    "    for key, value in summary.items():\n",
    "        print(f\"{key}: {value:,}\" if isinstance(value, int) else f\"{key}: {value}\")\n",
    "    \n",
    "    print(\"\\n=== CATEGORIES ===\")\n",
    "    category_counts.show(20)\n",
    "    \n",
    "    # Save category list for later use\n",
    "    category_counts.coalesce(1).write.mode(\"overwrite\").parquet(f\"{intermediate_bucket}/category_distribution\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a987dc1-2213-41ef-aae3-b2d37cb8d35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_full_meta_data():\n",
    "    \"\"\"Process the full metadata dataset with basic transformations\"\"\"\n",
    "    # Load full metadata\n",
    "    df_meta = spark.read.parquet(os.path.join(gcs_folder, 'meta_parquet'))\n",
    "    \n",
    "    # Basic preprocessing - clean up price field and explode categories\n",
    "    df_meta_processed = df_meta.withColumn(\n",
    "        \"price_clean\", \n",
    "        F.regexp_replace(F.col(\"price\"), \"\\\\$\", \"\").cast(\"float\")\n",
    "    )\n",
    "    \n",
    "    # Ensure parent_asin is not null\n",
    "    df_meta_clean = df_meta_processed.filter(F.col(\"parent_asin\").isNotNull())\n",
    "    \n",
    "    # Save processed data\n",
    "    df_meta_clean.write.mode(\"overwrite\").parquet(f\"{intermediate_bucket}/meta_processed\")\n",
    "    print(f\"Processed {df_meta_clean.count():,} metadata records and saved to {intermediate_bucket}/meta_processed\")\n",
    "    \n",
    "    return df_meta_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27d072df-138d-48bb-965d-f745ead60631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate bucket already exists: gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project\n"
     ]
    }
   ],
   "source": [
    "create_intermediate_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2d67b0f-124b-4d2f-a0ad-bbc548a7fe81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:===================================================>   (93 + 7) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 64,679,785 review records and saved to gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/reviews_processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews_processed = process_full_reviews_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eba36c3-2f87-496b-9ce1-785fd135463f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:===================================================>    (23 + 2) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4,320,533 metadata records and saved to gs://msca-bdp-students-bucket/shared_data/apavlovic/final_project/meta_processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "meta_processed = process_full_meta_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9df9120-9553-44ec-976d-cfbc706d8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_dataset(sample_fraction=0.01):\n",
    "    \"\"\"Create a smaller development dataset for faster iteration\"\"\"\n",
    "    print(f\"Creating {sample_fraction*100}% development dataset...\")\n",
    "    \n",
    "    # Sample reviews\n",
    "    reviews_df = spark.read.parquet(f\"{intermediate_bucket}/reviews_processed\")\n",
    "    reviews_sample = reviews_df.sample(fraction=sample_fraction, seed=42)\n",
    "    \n",
    "    # Get corresponding products\n",
    "    sampled_asins = reviews_sample.select(\"parent_asin\").distinct()\n",
    "    meta_df = spark.read.parquet(f\"{intermediate_bucket}/meta_processed\")\n",
    "    meta_sample = meta_df.join(sampled_asins, on=\"parent_asin\", how=\"inner\")\n",
    "    \n",
    "    # Save dev datasets\n",
    "    reviews_sample.repartition(10).write.mode(\"overwrite\").parquet(f\"{intermediate_bucket}/reviews_dev\")\n",
    "    meta_sample.repartition(5).write.mode(\"overwrite\").parquet(f\"{intermediate_bucket}/meta_dev\")\n",
    "    \n",
    "    print(f\"Dev dataset created:\")\n",
    "    print(f\"  - Reviews: {reviews_sample.count():,} records\")\n",
    "    print(f\"  - Products: {meta_sample.count():,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24998264-83f3-45b3-9093-93aeb464ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_processed_data():\n",
    "    \"\"\"Quick validation of processed data\"\"\"\n",
    "    print(\"Validating processed data...\")\n",
    "    \n",
    "    reviews_df = spark.read.parquet(f\"{intermediate_bucket}/reviews_processed\")\n",
    "    \n",
    "    # Check for duplicates using combination of columns that should be unique\n",
    "    total_records = reviews_df.count()\n",
    "    unique_records = reviews_df.dropDuplicates([\"user_id\", \"parent_asin\", \"timestamp\"]).count()\n",
    "    \n",
    "    print(f\"Total records: {total_records:,}\")\n",
    "    print(f\"Unique records (by user/product/time): {unique_records:,}\")\n",
    "    print(f\"Potential duplicates: {total_records - unique_records:,}\")\n",
    "    \n",
    "    # Check for data quality issues\n",
    "    null_counts = reviews_df.select([\n",
    "        F.sum(F.col(c).isNull().cast(\"int\")).alias(c) \n",
    "        for c in [\"parent_asin\", \"user_id\", \"rating\", \"timestamp\", \"text\", \"title\"]\n",
    "    ]).collect()[0]\n",
    "    \n",
    "    print(\"\\nNull counts per column:\")\n",
    "    for col in [\"parent_asin\", \"user_id\", \"rating\", \"timestamp\", \"text\", \"title\"]:\n",
    "        print(f\"  {col}: {null_counts[col]:,}\")\n",
    "    \n",
    "    # Rating distribution\n",
    "    print(\"\\nRating distribution:\")\n",
    "    reviews_df.groupBy(\"rating\").count().orderBy(\"rating\").show()\n",
    "    \n",
    "    # Show sample of timestamp values to verify conversion\n",
    "    print(\"\\nSample timestamps:\")\n",
    "    reviews_df.select(\n",
    "        F.col(\"timestamp\"),\n",
    "        F.from_unixtime(F.col(\"timestamp\")/1000).alias(\"readable_date\")\n",
    "    ).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72a9689e-7fd6-4512-909c-01c47b674099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating summary statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA SUMMARY ===\n",
      "total_reviews: 64,679,785\n",
      "total_products: 4,320,533\n",
      "unique_reviewers: 22,789,619\n",
      "unique_products: 4,320,211\n",
      "date_range: 1998-01-19 to 2023-09-13\n",
      "\n",
      "=== CATEGORIES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|       main_category|  count|\n",
      "+--------------------+-------+\n",
      "|          Automotive|1719649|\n",
      "|Cell Phones & Acc...|1051457|\n",
      "|          All Beauty| 739608|\n",
      "|                NULL| 249444|\n",
      "|Tools & Home Impr...|  81103|\n",
      "|         Amazon Home|  79311|\n",
      "|Health & Personal...|  78383|\n",
      "|Industrial & Scie...|  69175|\n",
      "|      AMAZON FASHION|  68949|\n",
      "|     All Electronics|  54489|\n",
      "|      Premium Beauty|  34910|\n",
      "|   Sports & Outdoors|  27718|\n",
      "|           Computers|  11031|\n",
      "|     Car Electronics|   7797|\n",
      "|               Books|   6249|\n",
      "|      Camera & Photo|   6139|\n",
      "|     Office Products|   5269|\n",
      "|        Toys & Games|   5246|\n",
      "|Home Audio & Theater|   4447|\n",
      "|Arts, Crafts & Se...|   4356|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_stats = create_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17257a81-b0e5-47cf-b90a-126ae8db3188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating processed data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 64,679,785\n",
      "Unique records (by user/product/time): 63,968,446\n",
      "Potential duplicates: 711,339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null counts per column:\n",
      "  parent_asin: 0\n",
      "  user_id: 0\n",
      "  rating: 0\n",
      "  timestamp: 0\n",
      "  text: 0\n",
      "  title: 0\n",
      "\n",
      "Rating distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|rating|   count|\n",
      "+------+--------+\n",
      "|   1.0| 7945517|\n",
      "|   2.0| 3378242|\n",
      "|   3.0| 4444637|\n",
      "|   4.0| 7235328|\n",
      "|   5.0|41676061|\n",
      "+------+--------+\n",
      "\n",
      "\n",
      "Sample timestamps:\n",
      "+-------------+-------------------+\n",
      "|timestamp    |readable_date      |\n",
      "+-------------+-------------------+\n",
      "|1453819207000|2016-01-26 14:40:07|\n",
      "|1600341347791|2020-09-17 11:15:47|\n",
      "|1607280179211|2020-12-06 18:42:59|\n",
      "|1609835116809|2021-01-05 08:25:16|\n",
      "|1520895879064|2018-03-12 23:04:39|\n",
      "+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "589adf41-455e-4a19-b36b-573e33d59d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 10.0% development dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset created:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Reviews: 6,468,523 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:=============================================>         (20 + 4) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Products: 1,424,997 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "create_dev_dataset(sample_fraction=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e9b86d8-893b-40f4-b7ac-e2a5e2de8006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "9c39b79e5d2e7072beb4bd59-runtime-000091a417d9",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "bdp-student-template on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-000091a417d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
